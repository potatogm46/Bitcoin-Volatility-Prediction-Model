{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce938c6b-7533-49cb-99e9-2fbf52159386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FOMC Statement Scraper - January 2020 to October 29, 2025\n",
      "============================================================\n",
      "Fetching links from calendar page...\n",
      "Found 8 panels on calendar page\n",
      "Fetching links from historical page...\n",
      "Total unique statement links found: 107\n",
      "\n",
      "Parsing 107 statements...\n",
      "  Processed 10/107...\n",
      "  Processed 20/107...\n",
      "  Processed 30/107...\n",
      "  Processed 40/107...\n",
      "  Processed 50/107...\n",
      "  Processed 60/107...\n",
      "  Processed 70/107...\n",
      "  Processed 80/107...\n",
      "  Processed 90/107...\n",
      "  Processed 100/107...\n",
      "\n",
      "Successfully parsed 45 statements\n",
      "\n",
      "Final dataset: 45 statements from 2020-01-29 00:00:00 to 2025-07-30 00:00:00\n",
      "\n",
      "PDF statements: 0\n",
      "HTML statements: 45\n",
      "Rate changes: 14 out of 45 meetings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meeting_date</th>\n",
       "      <th>meeting_date_parsed</th>\n",
       "      <th>statement_url</th>\n",
       "      <th>target_lower</th>\n",
       "      <th>target_upper</th>\n",
       "      <th>is_pdf</th>\n",
       "      <th>delta_lower</th>\n",
       "      <th>delta_upper</th>\n",
       "      <th>rate_changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1/29/2020</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3/3/2020</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3/15/2020</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3/15/2020</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3/23/2020</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4/29/2020</td>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6/10/2020</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7/29/2020</td>\n",
       "      <td>2020-07-29</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9/16/2020</td>\n",
       "      <td>2020-09-16</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>11/5/2020</td>\n",
       "      <td>2020-11-05</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>12/16/2020</td>\n",
       "      <td>2020-12-16</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1/27/2021</td>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3/17/2021</td>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4/28/2021</td>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6/16/2021</td>\n",
       "      <td>2021-06-16</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7/28/2021</td>\n",
       "      <td>2021-07-28</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>9/22/2021</td>\n",
       "      <td>2021-09-22</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>11/3/2021</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>12/15/2021</td>\n",
       "      <td>2021-12-15</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1/26/2022</td>\n",
       "      <td>2022-01-26</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   meeting_date meeting_date_parsed  \\\n",
       "34    1/29/2020          2020-01-29   \n",
       "35     3/3/2020          2020-03-03   \n",
       "37    3/15/2020          2020-03-15   \n",
       "36    3/15/2020          2020-03-15   \n",
       "38    3/23/2020          2020-03-23   \n",
       "39    4/29/2020          2020-04-29   \n",
       "40    6/10/2020          2020-06-10   \n",
       "41    7/29/2020          2020-07-29   \n",
       "42    9/16/2020          2020-09-16   \n",
       "43    11/5/2020          2020-11-05   \n",
       "44   12/16/2020          2020-12-16   \n",
       "26    1/27/2021          2021-01-27   \n",
       "27    3/17/2021          2021-03-17   \n",
       "28    4/28/2021          2021-04-28   \n",
       "29    6/16/2021          2021-06-16   \n",
       "30    7/28/2021          2021-07-28   \n",
       "31    9/22/2021          2021-09-22   \n",
       "32    11/3/2021          2021-11-03   \n",
       "33   12/15/2021          2021-12-15   \n",
       "19    1/26/2022          2022-01-26   \n",
       "\n",
       "                                        statement_url  target_lower  \\\n",
       "34  https://www.federalreserve.gov/newsevents/pres...           1.5   \n",
       "35  https://www.federalreserve.gov/newsevents/pres...           1.0   \n",
       "37  https://www.federalreserve.gov/newsevents/pres...           0.0   \n",
       "36  https://www.federalreserve.gov/newsevents/pres...           0.0   \n",
       "38  https://www.federalreserve.gov/newsevents/pres...           0.0   \n",
       "39  https://www.federalreserve.gov/newsevents/pres...           0.0   \n",
       "40  https://www.federalreserve.gov/newsevents/pres...           0.0   \n",
       "41  https://www.federalreserve.gov/newsevents/pres...           0.0   \n",
       "42  https://www.federalreserve.gov/newsevents/pres...           0.0   \n",
       "43  https://www.federalreserve.gov/newsevents/pres...           0.0   \n",
       "44  https://www.federalreserve.gov/newsevents/pres...           0.0   \n",
       "26  https://www.federalreserve.gov/newsevents/pres...           0.0   \n",
       "27  https://www.federalreserve.gov/newsevents/pres...           0.0   \n",
       "28  https://www.federalreserve.gov/newsevents/pres...           0.0   \n",
       "29  https://www.federalreserve.gov/newsevents/pres...           0.0   \n",
       "30  https://www.federalreserve.gov/newsevents/pres...           0.0   \n",
       "31  https://www.federalreserve.gov/newsevents/pres...           0.0   \n",
       "32  https://www.federalreserve.gov/newsevents/pres...           0.0   \n",
       "33  https://www.federalreserve.gov/newsevents/pres...           0.0   \n",
       "19  https://www.federalreserve.gov/newsevents/pres...           0.0   \n",
       "\n",
       "    target_upper  is_pdf  delta_lower  delta_upper  rate_changed  \n",
       "34          1.75   False          NaN          NaN             0  \n",
       "35          1.25   False         -0.5         -0.5             1  \n",
       "37          0.25   False         -1.0         -1.0             1  \n",
       "36          0.25   False          0.0          0.0             0  \n",
       "38          0.25   False          0.0          0.0             0  \n",
       "39          0.25   False          0.0          0.0             0  \n",
       "40          0.25   False          0.0          0.0             0  \n",
       "41          0.25   False          0.0          0.0             0  \n",
       "42          0.25   False          0.0          0.0             0  \n",
       "43          0.25   False          0.0          0.0             0  \n",
       "44          0.25   False          0.0          0.0             0  \n",
       "26          0.25   False          0.0          0.0             0  \n",
       "27          0.25   False          0.0          0.0             0  \n",
       "28          0.25   False          0.0          0.0             0  \n",
       "29          0.25   False          0.0          0.0             0  \n",
       "30          0.25   False          0.0          0.0             0  \n",
       "31          0.25   False          0.0          0.0             0  \n",
       "32          0.25   False          0.0          0.0             0  \n",
       "33          0.25   False          0.0          0.0             0  \n",
       "19          0.25   False          0.0          0.0             0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === FOMC STATEMENT SCRAPER: AUTOMATED DATA COLLECTION ===\n",
    "# This script performs web scraping to extract historical Federal Reserve data\n",
    "# Purpose: Automate collection of FOMC meeting dates and interest rate decisions\n",
    "# Alternative: Manual data entry (error-prone, time-consuming, not reproducible)\n",
    "\n",
    "# LIBRARY IMPORTS:\n",
    "# re: Regular expression module for pattern matching in text (interest rate extraction)\n",
    "import re\n",
    "# urllib.parse.urljoin: Handles relative URL resolution (converts href=\"/path\" to full URL)\n",
    "from urllib.parse import urljoin\n",
    "# datetime: Date parsing and manipulation for temporal data handling\n",
    "from datetime import datetime\n",
    "# io: In-memory binary streams for PDF processing (avoids disk I/O)\n",
    "import io\n",
    "\n",
    "# WEB SCRAPING STACK:\n",
    "# requests: HTTP library for fetching web pages (simpler than urllib, handles sessions)\n",
    "import requests\n",
    "# pandas: Data structure for organizing scraped data into tabular format\n",
    "import pandas as pd\n",
    "# BeautifulSoup: HTML/XML parser for navigating DOM tree and extracting data\n",
    "#   - Handles malformed HTML gracefully (unlike strict XML parsers)\n",
    "#   - Provides Pythonic API for tree traversal\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# PDF PARSING LIBRARIES (OPTIONAL):\n",
    "# FOMC statements exist in both HTML and PDF formats\n",
    "# We attempt to import PDF libraries with fallback handling\n",
    "try:\n",
    "    # PyPDF2: Pure-Python PDF library, lightweight but less robust\n",
    "    import PyPDF2\n",
    "    PDF_AVAILABLE = True\n",
    "except ImportError:\n",
    "    try:\n",
    "        # pdfplumber: More sophisticated PDF extraction (handles tables, layouts better)\n",
    "        # Built on top of pdfminer.six, better text extraction accuracy\n",
    "        import pdfplumber\n",
    "        PDF_AVAILABLE = True\n",
    "        PDF_LIB = 'pdfplumber'\n",
    "    except ImportError:\n",
    "        # Graceful degradation: Script continues without PDF support\n",
    "        # Only HTML statements will be processed (still captures majority of data)\n",
    "        PDF_AVAILABLE = False\n",
    "        PDF_LIB = None\n",
    "        print(\"Warning: PDF libraries not found. Install with: pip install PyPDF2 or pip install pdfplumber\")\n",
    "\n",
    "# === SCRAPING CONFIGURATION ===\n",
    "# WEB SCRAPING BEST PRACTICES:\n",
    "# 1. Use specific User-Agent to identify bot (ethical scraping)\n",
    "# 2. Respect robots.txt (Federal Reserve allows this)\n",
    "# 3. Use sessions to maintain connection pooling (efficiency)\n",
    "\n",
    "# Base URL for Federal Reserve website\n",
    "BASE = \"https://www.federalreserve.gov\"\n",
    "\n",
    "# TARGET ENDPOINTS:\n",
    "# Calendar page: Contains recent/upcoming FOMC meetings\n",
    "CAL_URL = f\"{BASE}/monetarypolicy/fomccalendars.htm\"\n",
    "# Historical page: Archive of past FOMC statements (2000s-2020s)\n",
    "HISTORICAL_URL = f\"{BASE}/monetarypolicy/fomc_historical.htm\"\n",
    "\n",
    "# HTTP HEADERS:\n",
    "# User-Agent: Identifies our scraper to server (prevents blocking)\n",
    "# Many websites block requests with default python-requests user agent\n",
    "# Using realistic browser string improves success rate\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"}\n",
    "\n",
    "# SESSION OBJECT:\n",
    "# requests.Session() provides:\n",
    "#   - Connection pooling (reuses TCP connections, faster)\n",
    "#   - Cookie persistence across requests\n",
    "#   - Header defaults applied to all requests\n",
    "SESSION = requests.Session()\n",
    "SESSION.headers.update(HEADERS)\n",
    "\n",
    "# TEMPORAL FILTERING:\n",
    "# Restrict data collection to analysis timeframe (2020-2025)\n",
    "# Matches the Bitcoin price data range in main analysis\n",
    "# datetime objects enable robust date comparisons\n",
    "START_DATE = datetime(2020, 1, 1)\n",
    "END_DATE = datetime(2025, 10, 29)\n",
    "\n",
    "# === REGULAR EXPRESSION PATTERNS FOR RATE EXTRACTION ===\n",
    "# NATURAL LANGUAGE PROCESSING CHALLENGE:\n",
    "# FOMC statements are written in formal English with varying phrasings\n",
    "# We need to extract structured data (interest rates) from unstructured text\n",
    "# Solution: Multiple regex patterns ordered by specificity (waterfall matching)\n",
    "\n",
    "# REGEX DESIGN PRINCIPLES:\n",
    "# 1. Most specific patterns first (avoid false positives)\n",
    "# 2. Case-insensitive matching (FOMC writing style varies)\n",
    "# 3. Flexible whitespace handling (\\s+ matches 1+ spaces/newlines)\n",
    "# 4. Capture groups () to extract rate values\n",
    "\n",
    "# CHARACTER CLASS: [\\d\\-\\s¼½¾/\\.]+ matches:\n",
    "#   \\d: digits 0-9\n",
    "#   \\-: dash (for formats like \"5-1/4\")\n",
    "#   \\s: whitespace\n",
    "#   ¼½¾: Unicode fraction characters (FOMC uses these)\n",
    "#   /: slash (for fractional notation like \"1/4\")\n",
    "#   \\.: decimal point\n",
    "#   +: one or more occurrences (greedy quantifier)\n",
    "\n",
    "RATE_PATTERNS = [\n",
    "    # PATTERN 1: Action verb + rate specification\n",
    "    # Example: \"decided to raise the target range for the federal funds rate to 0.25 to 0.50 percent\"\n",
    "    # (?:...) is non-capturing group (matches but doesn't create capture group)\n",
    "    # Captures: Two rate values (lower and upper bounds of range)\n",
    "    re.compile(\n",
    "        r\"(?:raise|lower|raised|lowered|set|decided to raise|decided to lower)\\s+the\\s+target\\s+range\\s+for\\s+the\\s+federal\\s+funds\\s+rate\\s+to\\s+([\\d\\-\\s¼½¾/\\.]+)\\s+to\\s+([\\d\\-\\s¼½¾/\\.]+)\\s+percent\",\n",
    "        re.IGNORECASE,\n",
    "    ),\n",
    "    \n",
    "    # PATTERN 2: Target range specification with \"to\" before values\n",
    "    # Example: \"target range for the federal funds rate to 1/4 to 1/2 percent\"\n",
    "    # This pattern catches statements that omit action verbs\n",
    "    re.compile(\n",
    "        r\"target\\s+range\\s+for\\s+the\\s+federal\\s+funds\\s+rate\\s+to\\s+([\\d\\-\\s¼½¾/\\.]+)\\s+to\\s+([\\d\\-\\s¼½¾/\\.]+)\\s+percent\",\n",
    "        re.IGNORECASE,\n",
    "    ),\n",
    "    \n",
    "    # PATTERN 3: Status quo statements (rate remains at X to Y)\n",
    "    # Example: \"target range for the federal funds rate remains at 0 to 1/4 percent\"\n",
    "    # (?:remains)? makes \"remains\" optional (present in no-change statements)\n",
    "    # \\s* allows zero or more spaces (flexible spacing)\n",
    "    re.compile(\n",
    "        r\"target\\s+range\\s+for\\s+the\\s+federal\\s+funds\\s+rate(?: remains)?(?: at)?\\s*(?:the )?(?:level of )?\\s+([\\d\\-\\s¼½¾/\\.]+)\\s*to\\s*([\\d\\-\\s¼½¾/\\.]+)\\s*percent\",\n",
    "        re.IGNORECASE,\n",
    "    ),\n",
    "    \n",
    "    # PATTERN 4: Abbreviated form (target range of X to Y)\n",
    "    # Example: \"target range of 2.25 to 2.50 percent\"\n",
    "    # More concise phrasing, often in summary sections\n",
    "    re.compile(\n",
    "        r\"target\\s+range\\s+(?:for the federal funds rate\\s+)?(?:of\\s+)?([\\d\\-\\s¼½¾/\\.]+)\\s+to\\s+([\\d\\-\\s¼½¾/\\.]+)\\s+percent\",\n",
    "        re.IGNORECASE,\n",
    "    ),\n",
    "    \n",
    "    # PATTERN 5: Simple rate statement (federal funds rate at X to Y)\n",
    "    # Example: \"federal funds rate at 4.50 to 4.75 percent\"\n",
    "    # Catches minimal phrasings\n",
    "    re.compile(\n",
    "        r\"federal\\s+funds\\s+rate\\s+(?:at\\s+)?([\\d\\-\\s¼½¾/\\.]+)\\s+to\\s+([\\d\\-\\s¼½¾/\\.]+)\\s+percent\",\n",
    "        re.IGNORECASE,\n",
    "    ),\n",
    "    \n",
    "    # PATTERN 6: Action with indirect specification (raised...to)\n",
    "    # Example: \"raised...federal funds rate...to 3.00 to 3.25 percent\"\n",
    "    # .*? is non-greedy match (matches minimum text between keywords)\n",
    "    # Catches sentences with intervening clauses\n",
    "    re.compile(\n",
    "        r\"(?:raised|lowered|set|maintained).*?federal\\s+funds\\s+rate.*?to\\s+([\\d\\-\\s¼½¾/\\.]+)\\s+to\\s+([\\d\\-\\s¼½¾/\\.]+)\\s+percent\",\n",
    "        re.IGNORECASE,\n",
    "    ),\n",
    "]\n",
    "\n",
    "def clean_rate(raw):\n",
    "    \"\"\"\n",
    "    Convert extracted rate string to float, handling diverse numerical formats.\n",
    "    \n",
    "    DATA QUALITY CHALLENGE:\n",
    "    FOMC statements use inconsistent number formatting:\n",
    "    - Decimal: \"0.25\", \"4.50\"\n",
    "    - Fractions: \"1/4\", \"1/2\", \"3/4\"\n",
    "    - Mixed: \"5-1/4\" (5.25), \"5 1/4\"\n",
    "    - Unicode: \"¼\", \"½\", \"¾\"\n",
    "    \n",
    "    This function normalizes all formats to Python float for analysis.\n",
    "    \"\"\"\n",
    "    # NULL HANDLING: Return None for missing/invalid data\n",
    "    if not raw or pd.isna(raw):\n",
    "        return None\n",
    "    \n",
    "    # UNICODE NORMALIZATION:\n",
    "    # Replace special fraction characters with decimal equivalents\n",
    "    # Common in Federal Reserve formal documents\n",
    "    repl = str(raw).replace(\"¼\", \".25\").replace(\"½\", \".50\").replace(\"¾\", \".75\")\n",
    "    repl = repl.replace(\" \", \"\").strip()  # Remove whitespace\n",
    "    \n",
    "    # CASE 1: MIXED NUMBER FORMAT (whole + fraction)\n",
    "    # Examples: \"5-1/4\" → 5.25, \"5 1/4\" → 5.25\n",
    "    # Algorithm: Parse whole number, parse fraction, add together\n",
    "    if (\"-\" in repl or \" \" in repl) and \"/\" in repl:\n",
    "        # Split on delimiter (dash or space)\n",
    "        if \"-\" in repl:\n",
    "            parts = repl.split(\"-\")\n",
    "        else:\n",
    "            parts = repl.split(\" \", 1)\n",
    "        \n",
    "        if len(parts) == 2:\n",
    "            # Extract whole number part\n",
    "            whole = float(parts[0]) if parts[0] else 0\n",
    "            frac_part = parts[1]\n",
    "            \n",
    "            # Parse fractional part (numerator/denominator)\n",
    "            if \"/\" in frac_part:\n",
    "                num, den = frac_part.split(\"/\")\n",
    "                try:\n",
    "                    fraction = float(num) / float(den)\n",
    "                    return whole + fraction  # Combine: 5 + 0.25 = 5.25\n",
    "                except (ValueError, ZeroDivisionError):\n",
    "                    pass  # Fall through to next parsing attempt\n",
    "            \n",
    "            # Fallback: Treat second part as decimal\n",
    "            try:\n",
    "                return whole + float(frac_part)\n",
    "            except ValueError:\n",
    "                pass\n",
    "    \n",
    "    # CASE 2: SIMPLE FRACTION FORMAT (no whole number)\n",
    "    # Examples: \"1/4\" → 0.25, \"1/2\" → 0.50, \"3/4\" → 0.75\n",
    "    if \"/\" in repl and \"-\" not in repl and \" \" not in repl:\n",
    "        try:\n",
    "            num, den = repl.split(\"/\")\n",
    "            return float(num) / float(den)\n",
    "        except (ValueError, ZeroDivisionError):\n",
    "            pass\n",
    "    \n",
    "    # CASE 3: STANDARD DECIMAL FORMAT\n",
    "    # Examples: \"0.25\", \"4.50\", \"5.25\"\n",
    "    # This is the simplest and most common case\n",
    "    try:\n",
    "        return float(repl)\n",
    "    except ValueError:\n",
    "        # FALLBACK: Extract first number sequence if direct parsing fails\n",
    "        # Regex: \\d+\\.?\\d* matches integer or decimal (e.g., \"123\" or \"12.34\")\n",
    "        numbers = re.findall(r'\\d+\\.?\\d*', repl)\n",
    "        if numbers:\n",
    "            try:\n",
    "                return float(numbers[0])\n",
    "            except ValueError:\n",
    "                pass\n",
    "    \n",
    "    # PARSING FAILED: Return None (will be filtered out in data cleaning)\n",
    "    return None\n",
    "\n",
    "def extract_text_from_pdf(pdf_url):\n",
    "    \"\"\"\n",
    "    Extract plain text from PDF file hosted on Federal Reserve website.\n",
    "    \n",
    "    PDF PROCESSING WORKFLOW:\n",
    "    1. Download PDF binary data via HTTP\n",
    "    2. Load into memory (io.BytesIO) - avoids disk I/O\n",
    "    3. Parse PDF structure to extract text\n",
    "    4. Concatenate all pages into single string\n",
    "    \n",
    "    WHY PDF EXTRACTION IS COMPLEX:\n",
    "    - PDFs store text in arbitrary coordinates (not sequential)\n",
    "    - Requires layout analysis to reconstruct reading order\n",
    "    - May contain images, embedded fonts, complex layouts\n",
    "    \"\"\"\n",
    "    # EARLY RETURN: Skip if PDF libraries not available\n",
    "    # Graceful degradation - script continues with HTML-only data\n",
    "    if not PDF_AVAILABLE:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # HTTP REQUEST: Download PDF binary content\n",
    "        # timeout=30: Prevent hanging on slow connections (networking best practice)\n",
    "        response = SESSION.get(pdf_url, timeout=30)\n",
    "        # raise_for_status(): Raise exception for 4xx/5xx HTTP errors\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # LIBRARY-SPECIFIC PARSING:\n",
    "        # We support two PDF libraries with different trade-offs\n",
    "        if PDF_LIB == 'pdfplumber':\n",
    "            # pdfplumber: Better text extraction accuracy, handles complex layouts\n",
    "            # Slower but more robust for government documents\n",
    "            import pdfplumber\n",
    "            # BytesIO: In-memory binary stream (no temporary file needed)\n",
    "            # Context manager (with) ensures proper resource cleanup\n",
    "            with pdfplumber.open(io.BytesIO(response.content)) as pdf:\n",
    "                # Extract text from each page, filter None values (empty pages)\n",
    "                # Join with newlines to preserve document structure\n",
    "                text = \"\\n\".join([page.extract_text() or \"\" for page in pdf.pages])\n",
    "            return text\n",
    "        else:\n",
    "            # PyPDF2: Faster, pure Python, lightweight\n",
    "            # Less accurate for complex layouts but sufficient for simple statements\n",
    "            pdf_file = io.BytesIO(response.content)\n",
    "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "            # Iterate through pages, extract text, concatenate\n",
    "            text = \"\\n\".join([page.extract_text() for page in pdf_reader.pages])\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        # ERROR HANDLING: PDF parsing can fail for many reasons:\n",
    "        # - Corrupted PDF, scanned images (no extractable text)\n",
    "        # - Network timeout, malformed PDF structure\n",
    "        # We log the error and return None (statement will be skipped)\n",
    "        print(f\"Error reading PDF {pdf_url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_date(date_str):\n",
    "    \"\"\"\n",
    "    Parse various date string formats into Python datetime object.\n",
    "    \n",
    "    DATE FORMAT HETEROGENEITY PROBLEM:\n",
    "    Federal Reserve website uses inconsistent date formatting:\n",
    "    - Formal: \"January 29, 2025\" (HTML pages)\n",
    "    - Numeric: \"01/29/2025\", \"1/29/2025\" (mixed sources)\n",
    "    - ISO: \"2025-01-29\" (some metadata)\n",
    "    - Variations: With/without commas, leading zeros\n",
    "    \n",
    "    This function provides robust parsing across all formats.\n",
    "    \"\"\"\n",
    "    # NULL HANDLING: Return None for missing dates\n",
    "    if pd.isna(date_str) or not date_str:\n",
    "        return None\n",
    "    \n",
    "    # REGEX PATTERN LIBRARY:\n",
    "    # Each pattern captures (month, day, year) in different formats\n",
    "    patterns = [\n",
    "        # PATTERN 1: Full month name (American English format)\n",
    "        # Examples: \"January 29, 2025\", \"March 15, 2020\"\n",
    "        # Capture groups: (month_name, day, year)\n",
    "        r\"([A-Z][a-z]+)\\s+(\\d{1,2}),?\\s+(\\d{4})\",\n",
    "        \n",
    "        # PATTERN 2: Numeric MM/DD/YYYY (US standard)\n",
    "        # Examples: \"01/29/2025\", \"3/15/2020\" (handles no leading zero)\n",
    "        # Capture groups: (month, day, year)\n",
    "        r\"(\\d{1,2})/(\\d{1,2})/(\\d{4})\",\n",
    "        \n",
    "        # PATTERN 3: ISO 8601 format YYYY-MM-DD (international standard)\n",
    "        # Examples: \"2025-01-29\", \"2020-03-15\"\n",
    "        # Capture groups: (year, month, day) - NOTE DIFFERENT ORDER\n",
    "        r\"(\\d{4})-(\\d{2})-(\\d{2})\",\n",
    "    ]\n",
    "    \n",
    "    # WATERFALL MATCHING: Try each pattern until one succeeds\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, str(date_str))\n",
    "        if match:\n",
    "            try:\n",
    "                # NUMERIC FORMATS (patterns with / or -)\n",
    "                if \"/\" in pattern or \"-\" in pattern:\n",
    "                    parts = match.groups()  # Extract captured groups\n",
    "                    if len(parts) == 3:\n",
    "                        # PATTERN-SPECIFIC PARSING:\n",
    "                        if \"/\" in pattern:\n",
    "                            # MM/DD/YYYY → extract in order\n",
    "                            month, day, year = parts\n",
    "                        else:\n",
    "                            # YYYY-MM-DD → reorder for datetime constructor\n",
    "                            year, month, day = parts\n",
    "                        # datetime(year, month, day) requires integer arguments\n",
    "                        return datetime(int(year), int(month), int(day))\n",
    "                \n",
    "                # TEXT FORMAT (month name pattern)\n",
    "                else:\n",
    "                    month_name, day, year = match.groups()\n",
    "                    # MONTH NAME LOOKUP TABLE:\n",
    "                    # Maps English month names to numeric values (1-12)\n",
    "                    # Case-insensitive via .lower()\n",
    "                    month_map = {\n",
    "                        'january': 1, 'february': 2, 'march': 3, 'april': 4,\n",
    "                        'may': 5, 'june': 6, 'july': 7, 'august': 8,\n",
    "                        'september': 9, 'october': 10, 'november': 11, 'december': 12\n",
    "                    }\n",
    "                    month = month_map.get(month_name.lower())\n",
    "                    if month:\n",
    "                        return datetime(int(year), month, int(day))\n",
    "            except (ValueError, KeyError):\n",
    "                # PARSING FAILED: Try next pattern\n",
    "                # ValueError: Invalid date (e.g., February 30)\n",
    "                # KeyError: Month name not in lookup table\n",
    "                continue\n",
    "    \n",
    "    # FALLBACK: Use pandas' robust date parser\n",
    "    # pd.to_datetime handles many edge cases we might miss\n",
    "    # errors='coerce': Return NaT (Not a Time) instead of raising exception\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, errors='coerce')\n",
    "    except:\n",
    "        # COMPLETE FAILURE: Return None (will be filtered out later)\n",
    "        return None\n",
    "\n",
    "def fetch_all_statement_links():\n",
    "    \"\"\"\n",
    "    Fetch all FOMC statement links from Federal Reserve website.\n",
    "    \n",
    "    WEB SCRAPING STRATEGY:\n",
    "    Federal Reserve organizes FOMC statements across two pages:\n",
    "    1. Calendar page: Recent/upcoming meetings (2023-2025)\n",
    "    2. Historical page: Archive of all past meetings (1990s-present)\n",
    "    \n",
    "    We scrape both to ensure complete coverage of our analysis period.\n",
    "    \n",
    "    Returns:\n",
    "        list: Dictionaries with keys: meeting_date_str, statement_url, is_pdf\n",
    "    \"\"\"\n",
    "    # DATA STRUCTURES:\n",
    "    all_meetings = []  # Accumulator for all discovered statements\n",
    "    seen_urls = set()  # Deduplication (some URLs appear on both pages)\n",
    "    \n",
    "    # === SCRAPING SOURCE 1: CALENDAR PAGE ===\n",
    "    # Contains structured meeting information in HTML panels\n",
    "    print(\"Fetching links from calendar page...\")\n",
    "    try:\n",
    "        # HTTP GET REQUEST:\n",
    "        # timeout=20: Fail after 20 seconds (prevent infinite hangs)\n",
    "        resp = SESSION.get(CAL_URL, timeout=20)\n",
    "        resp.raise_for_status()  # Raise exception for 4xx/5xx errors\n",
    "        \n",
    "        # HTML PARSING:\n",
    "        # BeautifulSoup converts HTML string to navigable tree structure\n",
    "        # \"html.parser\": Built-in Python parser (no external dependencies)\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        \n",
    "        # CSS SELECTOR: Find meeting information containers\n",
    "        # \".panel.panel-default\" targets Bootstrap panel components\n",
    "        # Each panel = one FOMC meeting with date and associated links\n",
    "        blocks = soup.select(\".panel.panel-default\")\n",
    "        print(f\"Found {len(blocks)} panels on calendar page\")\n",
    "        \n",
    "        # ITERATE THROUGH MEETING PANELS:\n",
    "        for block in blocks:\n",
    "            # EXTRACT MEETING DATE:\n",
    "            # Date typically in header tag (h3, h4, or h5)\n",
    "            # Fallback chain: try h5 first, then h4, then h3\n",
    "            header = block.find(\"h5\") or block.find(\"h4\") or block.find(\"h3\")\n",
    "            if not header:\n",
    "                continue  # Skip panels without recognizable headers\n",
    "            \n",
    "            date_text = header.get_text(strip=True)\n",
    "            \n",
    "            # FIND STATEMENT LINKS WITHIN PANEL:\n",
    "            # Each meeting has multiple documents (statement, minutes, projections)\n",
    "            # We specifically want the policy statement\n",
    "            for link in block.select(\"a\"):\n",
    "                href = link.get(\"href\", \"\")  # Get URL (default empty string if missing)\n",
    "                text = link.get_text(strip=True).lower()  # Link text for filtering\n",
    "                \n",
    "                # HEURISTIC FILTERING: Identify statement links\n",
    "                # Multiple conditions to handle varying HTML structures across years\n",
    "                is_statement = (\n",
    "                    # Condition 1: Link text contains \"statement\" AND URL mentions FOMC\n",
    "                    (\"statement\" in text and \"fomc\" in href.lower()) or\n",
    "                    # Condition 2: URL path indicates monetary policy press release\n",
    "                    \"pressreleases/monetary\" in href.lower() or\n",
    "                    # Condition 3: URL in statements directory with relevant text\n",
    "                    (\"fomcstatements\" in href.lower() and (\"statement\" in text or \"htm\" in href.lower() or \"pdf\" in href.lower()))\n",
    "                )\n",
    "                \n",
    "                # EXCLUSION FILTERS: Remove non-statement links\n",
    "                # \"calendar\": Links back to calendar page (not statements)\n",
    "                # \"minutes\": Meeting minutes (different document type)\n",
    "                if is_statement and \"calendar\" not in href.lower() and \"minutes\" not in href.lower():\n",
    "                    # URL NORMALIZATION: Convert relative URLs to absolute\n",
    "                    # urljoin() handles: \"/path\" → \"https://www.federalreserve.gov/path\"\n",
    "                    full_url = urljoin(BASE, href) if not href.startswith(\"http\") else href\n",
    "                    \n",
    "                    # DEDUPLICATION: Check if we've seen this URL before\n",
    "                    # set lookup is O(1) average case (hash table)\n",
    "                    if full_url not in seen_urls:\n",
    "                        seen_urls.add(full_url)\n",
    "                        all_meetings.append({\n",
    "                            \"meeting_date_str\": date_text,\n",
    "                            \"statement_url\": full_url,\n",
    "                            \"is_pdf\": href.lower().endswith(\".pdf\")  # Format detection\n",
    "                        })\n",
    "    except Exception as e:\n",
    "        # ERROR HANDLING: Network failures, HTML structure changes\n",
    "        # We continue execution (historical page might still work)\n",
    "        print(f\"Error fetching calendar page: {e}\")\n",
    "    \n",
    "    # === SCRAPING SOURCE 2: HISTORICAL ARCHIVE ===\n",
    "    # Different HTML structure than calendar page (less structured)\n",
    "    # Contains older statements going back to 1990s\n",
    "    print(\"Fetching links from historical page...\")\n",
    "    try:\n",
    "        resp = SESSION.get(HISTORICAL_URL, timeout=20)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        \n",
    "        # LESS STRUCTURED SCRAPING:\n",
    "        # Historical page lacks panel structure, so we search all links\n",
    "        # More false positives possible, hence stricter filtering\n",
    "        for link in soup.select(\"a\"):\n",
    "            href = link.get(\"href\", \"\")\n",
    "            text = link.get_text(strip=True)\n",
    "            \n",
    "            # STATEMENT IDENTIFICATION:\n",
    "            # Combine URL path check with text content check\n",
    "            # Both conditions must be true (AND logic) to reduce false positives\n",
    "            if (\"fomcstatements\" in href.lower() or \"pressreleases/monetary\" in href.lower()) and \\\n",
    "               (\"statement\" in text.lower() or \"htm\" in href.lower() or \"pdf\" in href.lower()):\n",
    "                \n",
    "                # URL NORMALIZATION:\n",
    "                full_url = urljoin(BASE, href) if not href.startswith(\"http\") else href\n",
    "                \n",
    "                # DEDUPLICATION: Skip if already found on calendar page\n",
    "                if full_url not in seen_urls:\n",
    "                    # DATE EXTRACTION CHALLENGE:\n",
    "                    # Historical page doesn't always have structured date fields\n",
    "                    # Strategy: Extract from URL filename (YYYYMMDD format) or link text\n",
    "                    \n",
    "                    # ATTEMPT 1: Parse date from URL\n",
    "                    # Example: \"/fomcstatements/20200129.htm\" → 2020-01-29\n",
    "                    date_match = re.search(r\"(\\d{4})(\\d{2})(\\d{2})\", href)\n",
    "                    if date_match:\n",
    "                        year, month, day = date_match.groups()\n",
    "                        # Convert to MM/DD/YYYY format for consistency\n",
    "                        date_text = f\"{int(month)}/{int(day)}/{year}\"\n",
    "                    else:\n",
    "                        # ATTEMPT 2: Extract date from link text\n",
    "                        # Example: \"January 29, 2020 Statement\"\n",
    "                        date_match = re.search(r\"([A-Z][a-z]+ \\d{1,2},? \\d{4})\", text)\n",
    "                        # Fallback: Use first 50 chars of link text if no date found\n",
    "                        date_text = date_match.group(1) if date_match else text[:50]\n",
    "                    \n",
    "                    seen_urls.add(full_url)\n",
    "                    all_meetings.append({\n",
    "                        \"meeting_date_str\": date_text,\n",
    "                        \"statement_url\": full_url,\n",
    "                        \"is_pdf\": href.lower().endswith(\".pdf\")\n",
    "                    })\n",
    "    except Exception as e:\n",
    "        # ERROR HANDLING: Same as calendar page\n",
    "        print(f\"Error fetching historical page: {e}\")\n",
    "    \n",
    "    # SUMMARY OUTPUT:\n",
    "    print(f\"Total unique statement links found: {len(all_meetings)}\")\n",
    "    return all_meetings\n",
    "\n",
    "def parse_statement(entry):\n",
    "    \"\"\"\n",
    "    Parse single FOMC statement and extract structured data.\n",
    "    \n",
    "    INFORMATION EXTRACTION PIPELINE:\n",
    "    1. Fetch statement content (HTML or PDF)\n",
    "    2. Extract release date from metadata\n",
    "    3. Extract body text from paragraphs\n",
    "    4. Apply regex patterns to find interest rate values\n",
    "    5. Clean and convert rate strings to floats\n",
    "    6. Return structured dictionary\n",
    "    \n",
    "    Args:\n",
    "        entry: Dict with keys 'statement_url', 'is_pdf', 'meeting_date_str'\n",
    "    \n",
    "    Returns:\n",
    "        Dict with parsed data or None if parsing fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = entry[\"statement_url\"]\n",
    "        is_pdf = entry.get(\"is_pdf\", False)\n",
    "        \n",
    "        # === STEP 1: CONTENT EXTRACTION ===\n",
    "        # Different extraction logic for PDF vs HTML\n",
    "        if is_pdf:\n",
    "            body_text = extract_text_from_pdf(url)\n",
    "            if not body_text:\n",
    "                return None  # PDF extraction failed\n",
    "        else:\n",
    "            # HTML EXTRACTION WORKFLOW:\n",
    "            res = SESSION.get(url, timeout=20)\n",
    "            res.raise_for_status()\n",
    "            soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "            \n",
    "            # === STEP 2: DATE EXTRACTION ===\n",
    "            # Federal Reserve uses different HTML classes across years\n",
    "            # CSS selector with fallback chain (comma-separated alternatives)\n",
    "            release_date_elem = soup.select_one(\".article__date, .releaseDate, time, .col-xs-12.col-sm-8 time\")\n",
    "            if release_date_elem:\n",
    "                release_date = release_date_elem.get_text(strip=True)\n",
    "            else:\n",
    "                # FALLBACK 1: Extract date from URL filename\n",
    "                # Example: \"20200129a.htm\" → \"01/29/2020\"\n",
    "                date_match = re.search(r\"(\\d{4})(\\d{2})(\\d{2})\", url)\n",
    "                if date_match:\n",
    "                    year, month, day = date_match.groups()\n",
    "                    release_date = f\"{int(month)}/{int(day)}/{year}\"\n",
    "                else:\n",
    "                    # FALLBACK 2: Use date from link discovery phase\n",
    "                    release_date = entry[\"meeting_date_str\"]\n",
    "            \n",
    "            # === STEP 3: BODY TEXT EXTRACTION ===\n",
    "            # HTML STRUCTURE VARIATIONS:\n",
    "            # Federal Reserve redesigned website multiple times (2000s, 2010s, 2020s)\n",
    "            # Each redesign uses different CSS classes for content\n",
    "            # We try selectors in order of specificity (most specific first)\n",
    "            \n",
    "            # ATTEMPT 1: Modern layout (2020s) - specific column structure\n",
    "            paragraph_nodes = soup.select(\"div.col-xs-12.col-sm-8 p\")\n",
    "            if not paragraph_nodes:\n",
    "                # ATTEMPT 2: Semantic HTML5 layout (2010s)\n",
    "                paragraph_nodes = soup.select(\"article p\")\n",
    "            if not paragraph_nodes:\n",
    "                # ATTEMPT 3: Bootstrap panel layout\n",
    "                paragraph_nodes = soup.select(\"div.panel-body p\")\n",
    "            if not paragraph_nodes:\n",
    "                # ATTEMPT 4: Generic fallback (any paragraph)\n",
    "                # Less precise but catches edge cases\n",
    "                paragraph_nodes = soup.select(\"p\")\n",
    "            \n",
    "            # TEXT CONCATENATION:\n",
    "            # Join paragraphs with spaces, normalize whitespace\n",
    "            # This creates single searchable string for regex matching\n",
    "            body_text = \" \".join(p.get_text(\" \", strip=True) for p in paragraph_nodes)\n",
    "        \n",
    "        # DATA QUALITY CHECK:\n",
    "        # Statements should be substantial (>100 chars)\n",
    "        # This filters out empty pages, error pages, navigation elements\n",
    "        if not body_text or len(body_text) < 100:\n",
    "            return None\n",
    "        \n",
    "        # === STEP 4: RATE EXTRACTION VIA REGEX ===\n",
    "        # WATERFALL PATTERN MATCHING:\n",
    "        # Try each pattern until one succeeds (ordered by specificity)\n",
    "        match = None\n",
    "        for pattern in RATE_PATTERNS:\n",
    "            match = pattern.search(body_text)\n",
    "            if match:\n",
    "                break  # Stop at first match (most specific pattern wins)\n",
    "        \n",
    "        if not match:\n",
    "            return None  # No rate information found (unusual but possible)\n",
    "        \n",
    "        # === STEP 5: RATE CLEANING AND CONVERSION ===\n",
    "        # REGEX CAPTURE GROUPS:\n",
    "        # match.group(1) = lower bound of target range\n",
    "        # match.group(2) = upper bound of target range\n",
    "        lower_raw = match.group(1).strip()\n",
    "        upper_raw = match.group(2).strip()\n",
    "        \n",
    "        # NORMALIZATION: Convert strings to floats\n",
    "        # Handles fractions, decimals, special characters\n",
    "        lower = clean_rate(lower_raw)\n",
    "        upper = clean_rate(upper_raw)\n",
    "        \n",
    "        # VALIDATION: Both rates must parse successfully\n",
    "        # Federal Funds Rate is always a range (e.g., 0.00-0.25%)\n",
    "        if lower is None or upper is None:\n",
    "            return None\n",
    "        \n",
    "        # === STEP 6: DATE PARSING ===\n",
    "        # Convert date string to datetime object for filtering/sorting\n",
    "        parsed_date = parse_date(release_date)\n",
    "        \n",
    "        # === OUTPUT: STRUCTURED DATA ===\n",
    "        # Return dictionary with all extracted information\n",
    "        # This will become one row in our pandas DataFrame\n",
    "        return {\n",
    "            \"meeting_date\": release_date,  # Original string\n",
    "            \"meeting_date_parsed\": parsed_date,  # datetime object\n",
    "            \"statement_url\": url,\n",
    "            \"target_lower\": lower,  # Float (e.g., 0.25)\n",
    "            \"target_upper\": upper,  # Float (e.g., 0.50)\n",
    "            \"is_pdf\": is_pdf\n",
    "        }\n",
    "    except Exception as e:\n",
    "        # COMPREHENSIVE ERROR HANDLING:\n",
    "        # Catches: Network errors, HTML parsing failures, regex errors, type conversions\n",
    "        # We log error but return None (skip this statement, continue with others)\n",
    "        print(f\"Error parsing {entry['statement_url']}: {e}\")\n",
    "        return None\n",
    "\n",
    "# === MAIN EXECUTION: DATA COLLECTION PIPELINE ===\n",
    "# This orchestrates the complete scraping workflow:\n",
    "# 1. Discover statement URLs\n",
    "# 2. Parse each statement\n",
    "# 3. Clean and structure data\n",
    "# 4. Compute derived features (rate changes)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FOMC Statement Scraper - January 2020 to October 29, 2025\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# === PHASE 1: LINK DISCOVERY ===\n",
    "# Crawl Federal Reserve website to find all FOMC statement URLs\n",
    "# Returns list of dictionaries with URL, date, format metadata\n",
    "all_links = fetch_all_statement_links()\n",
    "\n",
    "# === PHASE 2: CONTENT PARSING ===\n",
    "# Extract structured data from each statement\n",
    "# This is the most time-consuming phase (HTTP requests + parsing)\n",
    "print(f\"\\nParsing {len(all_links)} statements...\")\n",
    "rows = []  # Accumulator for successfully parsed statements\n",
    "for i, link in enumerate(all_links, 1):\n",
    "    # PROGRESS REPORTING: Print status every 10 statements\n",
    "    # Helps monitor long-running scraping jobs\n",
    "    if i % 10 == 0:\n",
    "        print(f\"  Processed {i}/{len(all_links)}...\")\n",
    "    \n",
    "    # PARSE INDIVIDUAL STATEMENT:\n",
    "    # Returns dict or None (if parsing failed)\n",
    "    parsed = parse_statement(link)\n",
    "    if parsed:\n",
    "        rows.append(parsed)  # Only keep successful parses\n",
    "\n",
    "print(f\"\\nSuccessfully parsed {len(rows)} statements\")\n",
    "\n",
    "# === PHASE 3: DATA STRUCTURING ===\n",
    "# Convert list of dictionaries to pandas DataFrame for analysis\n",
    "\n",
    "# ERROR HANDLING: Ensure we got at least some data\n",
    "if not rows:\n",
    "    raise ValueError(\"No statements parsed successfully!\")\n",
    "\n",
    "# CREATE DATAFRAME:\n",
    "# Each row = one FOMC meeting\n",
    "# Columns: meeting_date, statement_url, target_lower, target_upper, is_pdf\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# === PHASE 4: DATA CLEANING ===\n",
    "\n",
    "# DATE FILTERING:\n",
    "# Restrict to analysis timeframe (2020-2025) to match Bitcoin data\n",
    "# pd.to_datetime with errors='coerce': Invalid dates → NaT (Not a Time)\n",
    "df['meeting_date_parsed'] = pd.to_datetime(df['meeting_date_parsed'], errors='coerce')\n",
    "# Drop rows with unparseable dates\n",
    "df = df[df['meeting_date_parsed'].notna()]\n",
    "# Boolean indexing: Keep only dates within range\n",
    "df = df[(df['meeting_date_parsed'] >= START_DATE) & (df['meeting_date_parsed'] <= END_DATE)]\n",
    "\n",
    "# CHRONOLOGICAL SORTING:\n",
    "# Essential for time-series analysis (rate change calculation requires order)\n",
    "df = df.sort_values('meeting_date_parsed')\n",
    "\n",
    "# === PHASE 5: FEATURE ENGINEERING ===\n",
    "\n",
    "# RATE CHANGE CALCULATION:\n",
    "# diff() computes first difference: value[i] - value[i-1]\n",
    "# This shows how much rates changed from previous meeting\n",
    "# NaN in first row (no previous meeting to compare)\n",
    "df['delta_lower'] = df['target_lower'].diff()\n",
    "df['delta_upper'] = df['target_upper'].diff()\n",
    "\n",
    "# BINARY RATE CHANGE INDICATOR:\n",
    "# Create categorical variable: 1 = rate changed, 0 = rate unchanged\n",
    "# LOGIC: Rate changed if EITHER bound changed (and change is not NaN)\n",
    "# Why check both bounds? Rate changes always affect both symmetrically\n",
    "# Why check .notna()? First row has NaN delta (no previous meeting)\n",
    "df['rate_changed'] = (\n",
    "    ((df['delta_lower'].notna()) & (df['delta_lower'] != 0)) | \n",
    "    ((df['delta_upper'].notna()) & (df['delta_upper'] != 0))\n",
    ").astype(int)  # Convert boolean to 0/1\n",
    "\n",
    "# === PHASE 6: SUMMARY STATISTICS ===\n",
    "# Data quality reporting for validation\n",
    "print(f\"\\nFinal dataset: {len(df)} statements from {df['meeting_date_parsed'].min()} to {df['meeting_date_parsed'].max()}\")\n",
    "print(f\"\\nPDF statements: {df['is_pdf'].sum()}\")\n",
    "print(f\"HTML statements: {(~df['is_pdf']).sum()}\")\n",
    "print(f\"Rate changes: {df['rate_changed'].sum()} out of {len(df)} meetings\")\n",
    "\n",
    "# PREVIEW OUTPUT:\n",
    "# Display first 20 rows for visual inspection\n",
    "# Jupyter automatically renders DataFrame as formatted HTML table\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70bf39cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meeting_date</th>\n",
       "      <th>meeting_date_parsed</th>\n",
       "      <th>statement_url</th>\n",
       "      <th>target_lower</th>\n",
       "      <th>target_upper</th>\n",
       "      <th>is_pdf</th>\n",
       "      <th>delta_lower</th>\n",
       "      <th>delta_upper</th>\n",
       "      <th>rate_changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1/26/2022</td>\n",
       "      <td>2022-01-26</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3/16/2022</td>\n",
       "      <td>2022-03-16</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5/4/2022</td>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7/27/2022</td>\n",
       "      <td>2022-07-27</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.50</td>\n",
       "      <td>False</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9/21/2022</td>\n",
       "      <td>2022-09-21</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11/2/2022</td>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12/14/2022</td>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   meeting_date meeting_date_parsed  \\\n",
       "19    1/26/2022          2022-01-26   \n",
       "20    3/16/2022          2022-03-16   \n",
       "21     5/4/2022          2022-05-04   \n",
       "22    7/27/2022          2022-07-27   \n",
       "23    9/21/2022          2022-09-21   \n",
       "24    11/2/2022          2022-11-02   \n",
       "25   12/14/2022          2022-12-14   \n",
       "\n",
       "                                        statement_url  target_lower  \\\n",
       "19  https://www.federalreserve.gov/newsevents/pres...          0.00   \n",
       "20  https://www.federalreserve.gov/newsevents/pres...          0.25   \n",
       "21  https://www.federalreserve.gov/newsevents/pres...          0.75   \n",
       "22  https://www.federalreserve.gov/newsevents/pres...          2.25   \n",
       "23  https://www.federalreserve.gov/newsevents/pres...          3.00   \n",
       "24  https://www.federalreserve.gov/newsevents/pres...          3.75   \n",
       "25  https://www.federalreserve.gov/newsevents/pres...          4.25   \n",
       "\n",
       "    target_upper  is_pdf  delta_lower  delta_upper  rate_changed  \n",
       "19          0.25   False         0.00         0.00             0  \n",
       "20          0.50   False         0.25         0.25             1  \n",
       "21          1.00   False         0.50         0.50             1  \n",
       "22          2.50   False         1.50         1.50             1  \n",
       "23          3.25   False         0.75         0.75             1  \n",
       "24          4.00   False         0.75         0.75             1  \n",
       "25          4.50   False         0.50         0.50             1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === DATA VALIDATION: 2022 FOMC MEETINGS ===\n",
    "# EXPLORATORY ANALYSIS: Inspect specific year's data\n",
    "# 2022 was significant: Fed raised rates 7 times (0% → 4.5%) fighting inflation\n",
    "# This validates our scraper captured the aggressive tightening cycle\n",
    "\n",
    "# PANDAS DATETIME ACCESSOR:\n",
    "# .dt.year extracts year component from datetime column\n",
    "# Returns boolean mask: True for 2022 dates, False otherwise\n",
    "df[df['meeting_date_parsed'].dt.year == 2022]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56a17cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing rate extraction from sample text:\n",
      "Text: In support of these goals, the Committee decided to raise the target range for the federal funds rate to 1/4 to 1/2 percent\n",
      "\n",
      "✓ Pattern 1 MATCHED!\n",
      "  Lower: '1/4'\n",
      "  Upper: '1/2'\n",
      "  Parsed Lower: 0.25\n",
      "  Parsed Upper: 0.5\n",
      "\n",
      "============================================================\n",
      "Checking for March 16, 2022 in dataframe:\n",
      "Found March 16, 2022 statement:\n",
      "   meeting_date_parsed  target_lower  target_upper  rate_changed\n",
      "20          2022-03-16          0.25           0.5             1\n"
     ]
    }
   ],
   "source": [
    "# === REGEX PATTERN TESTING: UNIT TEST ===\n",
    "# SOFTWARE ENGINEERING BEST PRACTICE: Test complex functions in isolation\n",
    "# Purpose: Validate our regex patterns work on known input before full scraping\n",
    "# This is especially important for regex (easy to miss edge cases)\n",
    "\n",
    "# TEST CASE: March 16, 2022 statement (first rate hike of 2022 cycle)\n",
    "# This statement uses fractional notation \"1/4 to 1/2\" instead of decimals\n",
    "# Historical significance: First rate increase in 3 years (since 2019)\n",
    "test_text = \"In support of these goals, the Committee decided to raise the target range for the federal funds rate to 1/4 to 1/2 percent\"\n",
    "\n",
    "print(\"Testing rate extraction from sample text:\")\n",
    "print(f\"Text: {test_text}\\n\")\n",
    "\n",
    "# PATTERN MATCHING DIAGNOSTIC:\n",
    "# Try each regex pattern sequentially, report which one matches\n",
    "match = None\n",
    "for i, pattern in enumerate(RATE_PATTERNS, 1):\n",
    "    match = pattern.search(test_text)\n",
    "    if match:\n",
    "        print(f\"✓ Pattern {i} MATCHED!\")\n",
    "        print(f\"  Lower: '{match.group(1)}'\")  # Raw captured string\n",
    "        print(f\"  Upper: '{match.group(2)}'\")\n",
    "        \n",
    "        # TEST CLEANING FUNCTION:\n",
    "        # Verify fraction → decimal conversion works correctly\n",
    "        lower = clean_rate(match.group(1))\n",
    "        upper = clean_rate(match.group(2))\n",
    "        print(f\"  Parsed Lower: {lower}\")  # Should be 0.25\n",
    "        print(f\"  Parsed Upper: {upper}\")  # Should be 0.5\n",
    "        break\n",
    "\n",
    "if not match:\n",
    "    print(\"✗ No pattern matched!\")\n",
    "    # This would indicate our regex library is incomplete\n",
    "    \n",
    "# === CROSS-VALIDATION: Check scraper found this meeting ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Checking for March 16, 2022 in dataframe:\")\n",
    "\n",
    "# DATE FILTERING:\n",
    "# .dt.strftime('%Y-%m-%d') formats datetime as ISO string for exact comparison\n",
    "march_2022 = df[df['meeting_date_parsed'].dt.strftime('%Y-%m-%d') == '2022-03-16']\n",
    "\n",
    "if len(march_2022) > 0:\n",
    "    print(\"Found March 16, 2022 statement:\")\n",
    "    # Display parsed data to verify correctness\n",
    "    print(march_2022[['meeting_date_parsed', 'target_lower', 'target_upper', 'rate_changed']])\n",
    "else:\n",
    "    # DEBUGGING: If not found, show what 2022 dates we DO have\n",
    "    print(\"March 16, 2022 NOT found in dataframe\")\n",
    "    print(\"\\nAll 2022 statements:\")\n",
    "    print(df[df['meeting_date_parsed'].dt.year == 2022][['meeting_date_parsed', 'target_lower', 'target_upper', 'rate_changed']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92af98b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meeting_date</th>\n",
       "      <th>meeting_date_parsed</th>\n",
       "      <th>statement_url</th>\n",
       "      <th>target_lower</th>\n",
       "      <th>target_upper</th>\n",
       "      <th>is_pdf</th>\n",
       "      <th>delta_lower</th>\n",
       "      <th>delta_upper</th>\n",
       "      <th>rate_changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3/3/2020</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3/15/2020</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3/16/2022</td>\n",
       "      <td>2022-03-16</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5/4/2022</td>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7/27/2022</td>\n",
       "      <td>2022-07-27</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.50</td>\n",
       "      <td>False</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9/21/2022</td>\n",
       "      <td>2022-09-21</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11/2/2022</td>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12/14/2022</td>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2/1/2023</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.75</td>\n",
       "      <td>False</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3/22/2023</td>\n",
       "      <td>2023-03-22</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>4.75</td>\n",
       "      <td>5.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5/3/2023</td>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7/26/2023</td>\n",
       "      <td>2023-07-26</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12/18/2024</td>\n",
       "      <td>2024-12-18</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.75</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/29/2025</td>\n",
       "      <td>2025-01-29</td>\n",
       "      <td>https://www.federalreserve.gov/newsevents/pres...</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.50</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   meeting_date meeting_date_parsed  \\\n",
       "35     3/3/2020          2020-03-03   \n",
       "37    3/15/2020          2020-03-15   \n",
       "20    3/16/2022          2022-03-16   \n",
       "21     5/4/2022          2022-05-04   \n",
       "22    7/27/2022          2022-07-27   \n",
       "23    9/21/2022          2022-09-21   \n",
       "24    11/2/2022          2022-11-02   \n",
       "25   12/14/2022          2022-12-14   \n",
       "11     2/1/2023          2023-02-01   \n",
       "12    3/22/2023          2023-03-22   \n",
       "13     5/3/2023          2023-05-03   \n",
       "15    7/26/2023          2023-07-26   \n",
       "10   12/18/2024          2024-12-18   \n",
       "0     1/29/2025          2025-01-29   \n",
       "\n",
       "                                        statement_url  target_lower  \\\n",
       "35  https://www.federalreserve.gov/newsevents/pres...          1.00   \n",
       "37  https://www.federalreserve.gov/newsevents/pres...          0.00   \n",
       "20  https://www.federalreserve.gov/newsevents/pres...          0.25   \n",
       "21  https://www.federalreserve.gov/newsevents/pres...          0.75   \n",
       "22  https://www.federalreserve.gov/newsevents/pres...          2.25   \n",
       "23  https://www.federalreserve.gov/newsevents/pres...          3.00   \n",
       "24  https://www.federalreserve.gov/newsevents/pres...          3.75   \n",
       "25  https://www.federalreserve.gov/newsevents/pres...          4.25   \n",
       "11  https://www.federalreserve.gov/newsevents/pres...          4.50   \n",
       "12  https://www.federalreserve.gov/newsevents/pres...          4.75   \n",
       "13  https://www.federalreserve.gov/newsevents/pres...          5.00   \n",
       "15  https://www.federalreserve.gov/newsevents/pres...          5.25   \n",
       "10  https://www.federalreserve.gov/newsevents/pres...          4.50   \n",
       "0   https://www.federalreserve.gov/newsevents/pres...          4.25   \n",
       "\n",
       "    target_upper  is_pdf  delta_lower  delta_upper  rate_changed  \n",
       "35          1.25   False        -0.50        -0.50             1  \n",
       "37          0.25   False        -1.00        -1.00             1  \n",
       "20          0.50   False         0.25         0.25             1  \n",
       "21          1.00   False         0.50         0.50             1  \n",
       "22          2.50   False         1.50         1.50             1  \n",
       "23          3.25   False         0.75         0.75             1  \n",
       "24          4.00   False         0.75         0.75             1  \n",
       "25          4.50   False         0.50         0.50             1  \n",
       "11          4.75   False         0.25         0.25             1  \n",
       "12          5.00   False         0.25         0.25             1  \n",
       "13          5.25   False         0.25         0.25             1  \n",
       "15          5.50   False         0.25         0.25             1  \n",
       "10          4.75   False        -0.75        -0.75             1  \n",
       "0           4.50   False        -0.25        -0.25             1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === FILTERING FOR MONETARY POLICY ACTIONS ===\n",
    "# ECONOMIC INTERPRETATION:\n",
    "# Rate changes represent actual Federal Reserve policy interventions\n",
    "# These are the most market-moving FOMC meetings (vs status quo announcements)\n",
    "# Hypothesis: Bitcoin volatility higher on rate change days\n",
    "\n",
    "# BOOLEAN INDEXING:\n",
    "# Select only rows where rate_changed == 1 (policy action taken)\n",
    "# This should show:\n",
    "# - 2020: Emergency rate cuts during COVID (March 3, March 15)\n",
    "# - 2022-2023: Aggressive tightening cycle (7 hikes in 2022)\n",
    "# - 2024-2025: Rate cuts as inflation moderates\n",
    "df[df['rate_changed'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b31ab701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DATA EXPORT: Save for Bitcoin Volatility Analysis ===\n",
    "# PURPOSE: Create feature for main machine learning pipeline\n",
    "# This CSV will be loaded in Final_Project_.ipynb to create binary indicators\n",
    "\n",
    "# DATA SELECTION:\n",
    "# Extract only meeting_date_parsed column for rate change meetings\n",
    "# Why only this column? Main analysis only needs dates (not rate magnitudes)\n",
    "# This creates a clean lookup table: \"Was today a rate change day?\"\n",
    "\n",
    "# EXPORT PARAMETERS:\n",
    "# index=False: Don't write row numbers to CSV (unnecessary for date lookup)\n",
    "# Result: Single-column CSV with just dates of rate changes\n",
    "df[df['rate_changed'] == 1][['meeting_date_parsed']].to_csv('FOMC_Dates_with_Rate_Changes.csv', index=False)\n",
    "\n",
    "# OUTPUT FILE USAGE:\n",
    "# In main analysis: pd.read_csv('FOMC_Dates_with_Rate_Changes.csv')\n",
    "# Then: data['Is_FOMC_Day'] = data.index.isin(fomc_dates).astype(int)\n",
    "# This creates binary feature for supervised learning model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b636e66c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
